#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Sep 11 18:55:07 2023

@author: felipe
Arquivo com funcoes uteis do antigo calibrador que valem a pena serem guardadas para uso futuro, é interessante tambem perceber a possibilidade de 
se implementar elas a uma classe nova, que podera ser utilizada com a principal
"""

import os
import pandas as pd 
import xarray as xr
import plotly.graph_objs as go
import numpy as np 
import datetime

class Funcionalidades():
    
    def analise_sensibilidade(self,fator):
        lista = ["maps",
        "table2map",
        "meteo",
        "lai",
        # "maps/landuse",
        "maps/soilhyd"
        ]
        final = pd.DataFrame()
        for local in lista:
            diretorio = f"{self.OUT_DIR}/{local}"
            files = [x for x in os.listdir(diretorio) if x.endswith(".nc")]
            print(files)
            for arquivo in files:
                nome = arquivo.split(".")[0]  
                
                if nome =="" or nome =="area" or nome == "chans" or nome == "ec_ldd" or nome == "outlets":
                    continue
                dataset = xr.open_dataset(f"{diretorio}/{arquivo}")
                coluna = list(dataset.variables)[-1]
                dataset1 = dataset.copy()
                dataset1[coluna] = dataset[coluna] * fator
                
                os.remove(f"{diretorio}/{arquivo}")
                dataset1.to_netcdf(f"{diretorio}/{arquivo}")
                try:
                    os.remove(f"{self.OUT_DIR}/out/dis.nc")
                except Exception as erro:
                    print("error> " ,erro)
                os.system("lisflood ../settings.xml")
                
                result = pd.read_csv(f"{self.OUT_DIR}/out/chanqWin.tss",skiprows=3)
                lista = []
                indexer = result.columns.values[0]
                for i in result[indexer]:
                    valor = i.split()[1]
                    lista.append(float(valor))
                final[nome] = lista
        
                os.remove(f"{diretorio}/{arquivo}")
                dataset.to_netcdf(f"{diretorio}/{arquivo}")
                final.to_csv(f"./tabelas/resultados/analise_sensibilidade/_{fator}.csv")
                print(final)
        return final
        
    def compara_chuvas(self):
        meu = xr.open_dataset("/discolocal/felipe/lisflood_pm/catch/meteo/chuvas/pr_simepar.nc")
        era5 = xr.open_dataset("/discolocal/felipe/lisflood_pm/catch/meteo/chuvas/pr_era5_corrigido.nc")
        meu_ = meu.pr.resample(time='M').sum('time').to_dataframe()
        era5_ = era5.band_data.resample(time='M').sum('time').to_dataframe()
        
        meu_ = meu_.groupby(level=['time']).mean()
        era5_ = era5_.groupby(level=['time']).mean()
        
        df_merged = pd.DataFrame()
        
        df_merged = pd.merge(era5_,meu_,left_index = True,right_index = True)
        
        fig = go.Figure()
        fig.add_trace(go.Bar(x = df_merged.index , y = df_merged.band_data,name = "era5",marker_color = "red"))
        fig.add_trace(go.Bar(x= df_merged.index,y=df_merged.pr,name = "simepar", marker_color = "black"))
        fig.write_html("./comparacao_chuvas.html")
        
        
        return df_merged
    
    
    def plota_analise(self,df_place):
        # import plotly.graph_objs as go
        
        df = pd.read_csv(df_place,index_col = 0)
        nome = df_place.split("/")[-1]
        fig = go.Figure()   
        fig.add_trace(go.Scatter(x = df.index , y =  self._obs["horleitura"],name = "obs"))
        
        for coluna in df.columns:
    
            merged = self._obs
            merged["ls_dis"] = df[coluna].values
            targets = merged["horleitura"]
            predictions = merged["ls_dis"]
            nash_value = (1-(np.sum((targets-predictions)**2)/np.sum((targets-np.mean(targets))**2)))
            print(nash_value)
            fig.add_trace(go.Scatter(x = df.index , y = df[coluna],name = f"{coluna} _>{nash_value}"))
        fig.show()
        # fig.write_html(f"/discolocal/felipe/lisflood_pm/calibracao/tabelas/resultados/analise_sensibilidade/{nome}.html")
    
    def ativa_era5(self,ativar):
        if ativar == "ERA5":
            pr = xr.open_dataset("/discolocal/felipe/lisflood_pm/catch/meteo/chuvas/pr_era5_corrigido.nc")
            os.remove("/discolocal/felipe/lisflood_pm/catch/meteo/pr.nc")
            pr.to_netcdf("/discolocal/felipe/lisflood_pm/catch/meteo/pr.nc")
            print("Atualmente os dados do ERA5 estão implementados!")
        elif ativar == "simepar":
            pr = xr.open_dataset("/discolocal/felipe/lisflood_pm/catch/meteo/chuvas/pr_simepar.nc")
            os.remove("/discolocal/felipe/lisflood_pm/catch/meteo/pr.nc")
            pr.to_netcdf("/discolocal/felipe/lisflood_pm/catch/meteo/pr.nc")
            print("Atualmente os dados do simepar estão implementados!")
             
    def analisa_nova_chuva(self,df_chuvas):
        '''
        Programa responsavel por rodar diferentes chuvas dentro do lisflood, a fim de analisar quais apresentao maior representatividade da bacia
        Parameters
        ----------
        df_chuvas : Dataframe
        df com dados das chuvas que serão utilizados.
    
        Returns
        -------
        None.
       
        '''    
        base = xr.open_dataset("../catch/meteo/pr.nc")
        data = pd.date_range(start="2013-01-03 00:00:00",end = "2023-04-09 00:00:00",freq = "D" )
        df_final = pd.DataFrame(index = data)
        for coluna in df_chuvas.columns:
            
            temp = df_chuvas[coluna].to_frame()
            temp = temp["2013":"2023-04-07"]
            
       
            temp2 = base.copy()
            matrizes = []
           
            for _, row in temp.iterrows():
                matriz = np.full((12, 20), row[coluna])
                matrizes.append(matriz)
            temp2.pr.values = matrizes
       
            os.remove("../catch/meteo/pr.nc")
            temp2.to_netcdf("../catch/meteo/pr.nc")
            
            os.system(f"lisflood {self.SETTINGS_DIR}/settings.xml")
            
            
            self.plota(arquivo_saida = coluna)
            self.df.rename(columns ={"ls_dis":coluna},inplace = True)
            df_final = pd.merge(df_final,self.df,left_index=True,right_index=True,how = "outer")
            df_final.to_csv("./tabelas/resultados/analise_nova_chuva.csv")
            
    
    
    
    def ajustar_dimensao_temporal(self,ano):
        origem = "./params_calibration/meteo/"
        destino = "../catch/meteo/"
        arquivos = [arquivo for arquivo in os.listdir(origem) if arquivo.endswith('.nc')]
        saida = [arquivo for arquivo in os.listdir(destino) if arquivo.endswith('.nc')]
        for arquivo in saida:
            df = xr.open_dataset(os.path.join(destino, arquivo))
            print(df)
        for arquivo in arquivos:
            caminho_arquivo = os.path.join(origem, arquivo)
            dataset = xr.open_dataset(caminho_arquivo)
            data_selecionada = dataset.sel(time=slice(f"{ano}-01-01", f"{ano}-12-31"))
            dataset.close()
            
            novo_nome_arquivo = arquivo
            caminho_novo_arquivo = os.path.join(destino, novo_nome_arquivo)
            os.remove(caminho_novo_arquivo)
            data_selecionada.to_netcdf(caminho_novo_arquivo)
            print(f"Arquivo ajustado: {caminho_novo_arquivo}")
            
            
    def compara_multiplos_anosold(self,r = 0.2,m = 1000):
        caminho_arquivo = f"{self.SETTINGS_DIR}/compara_anos.xml"  # Substitua pelo caminho correto
        anos = [str(ano) for ano in range(2013, 2024)]  # Ano correspondente
        self.comparando_multiplos_anos = True
        for ano_alvo in anos:
            self.ajustar_parametros_ano(caminho_arquivo, ano_alvo)
            self.ajustar_dimensao_temporal(ano_alvo)
            self.reseta_for_the_best()
            self.executa(ano_alvo,["table2map"],r,m)
            
        self.comparando_multiplos_anos = False
        
    def executar_um_por_ano(self,r = 0.2,m = 1000):
        caminho_arquivo = f"{self.SETTINGS_DIR}/compara_anos.xml"  # Substitua pelo caminho correto
        anos = [str(ano) for ano in range(2013, 2024)]  # Ano correspondente
        self.comparando_multiplos_anos = True
        for ano_alvo in anos:
            self.ajustar_parametros_ano(caminho_arquivo, ano_alvo)
            self.ajustar_dimensao_temporal(ano_alvo)
            self.reseta_for_the_best()
            os.system(f"lisflood {caminho_arquivo}")
            self.ler_saida()
            self.nash_value = self.nash(False)
            self.arquivo_saida = ano_alvo
            self.plota_unico_file()
        self.comparando_multiplos_anos = False
    
    def plota_unico_file(self,recorta = False,plt_esp = False,arquivo_saida = False):
        local_pasta = f"{self.FILE_DIR}tabelas/resultados/plt_geral/"
        data_hoje = datetime.date.today()
        if plt_esp == False:
            self.pasta = f"{local_pasta}{data_hoje.day}_{data_hoje.month}/"
        elif plt_esp:
            self.pasta = f"{self.FILE_DIR}/tabelas/resultados/plt_esp/"
        with open(f'{local_pasta}/ano_a_ano.html', 'a') as f:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x = self.df_merged .index , y = self.df_merged .ls_dis,name = f"simulado {self.nome_grafico}: {self.nash_value}",marker_color = "red"))
            fig.add_trace(go.Scatter(x= self.df_merged .index,y=self.df_merged .horleitura,name = "obs", marker_color = "black"))
            fig.update_layout (
                title_text = self.arquivo_saida)
            if not os.path.exists(self.pasta ):
                os.makedirs(self.pasta )
                print(f"Pasta '{self.pasta }' criada com sucesso.")
            else:
                print(f"A pasta '{self.pasta }' já existe.")
    
            f.write(fig.to_html(full_html=False, include_plotlyjs='cdn'))
